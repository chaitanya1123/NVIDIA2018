{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My impressions from GTC Europe 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What?\n",
    "GPU Technology conference organized by NVIDIA Deep Learning Institute. You can check summary video [here](https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fgo.nvidianews.com%2FdE06ZMqMbX7Nq00Fn0100O0&data=01%7C01%7Cmima%40novozymes.com%7C07710586e0e246e26f8f08d63045ffba%7C43d5f49ee03a4d22a2285684196bb001%7C0&sdata=5Skd1VUte8XO%2BGXHvL3Z95ssH4lJ9CwIvq%2FDgQT62EI%3D&reserved=0)\n",
    "\n",
    "<img src=\"files/images/welcome.png\">\n",
    "\n",
    "## Where?\n",
    "Munich, Germany, Europe, Earth [48.136804 N, 11.692561E](https://goo.gl/maps/yk5Wy9NCggz)\n",
    "\n",
    "Weather conditions were very Southern European friendly:\n",
    "<img src=\"files/images/MunichWeather.png\">\n",
    "\n",
    "## When?\n",
    "October 09-11th 2018 (tragedy of the story is that Octoberfest ended on the 7th...)\n",
    "\n",
    "## Why?\n",
    "NVIDIA is the largest worldwide provider of GPUs (graphic processing units). Data science relies heavily on those for any kind of big data algorithm computations. On our alienware desktops in the office we use GeForce, NVIDIA Turing™ GPU architecture. Besides all the hardware considerations, NVIDIA Deep Learning Institute organizes training for deep learning topics in different domains. There was a range of training sessions offered at this year´s conference, see below for my summary of those I attended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Workshops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It all started with a day of workshops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning for Finance Trading Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had a bit of a hard time following the trading jargon, but what I wanted out of this session was details on the analytical setup. I had a certain project from my company in mind that I could try deep learning on. But the intro slide from the instructor kind of crushed my ideas already in the beginning. The quote in questions was about applying deep learning to simple problems with large datasets. \n",
    "\n",
    "\n",
    "_If a mental task is not easy, it is not going to be easy to implement aritificial intelligence on it. \n",
    "This is due to the hard task of labelling your data. @Andrew Ng_\n",
    "\n",
    "\n",
    "In other words, if a domain expert can phrase the problem in question as a simple equation, and given abundance of data, than the problem can be tackled with deep learning. However, if the problem is complex and you cannot formulate a simple answer to it, and few data is available, you don´t have to bother with deep learning. Applicability of AI can be described as a function of noise and structure in the data. As the structure decreases and noise increases, the applicability of AI algorithms to answer your questions to the problem posed decreases.\n",
    "\n",
    "As it usually goes, I got most out of the workshop through follow up discussions. Me and me companion next to me had a very vibrant discussion with the instructors regarding technical details of the setup of the network, and how you could transfer the learnings to other problems. We are still awaiting some follow up mails the instructors promissed to send on the questions we posed.\n",
    "\n",
    "This data lab was based on some good code, but not linked to the use cases they presented at all. I didn´t grasp how the algorithm presented was used to answer what should have been e.g. Apple´s trading strategy in the case of weak demand on iPhone X (one of the presented use cases). My general reflection on that was a revelation that it´s not only the Advanced Analytics team who sometimes struggle to explain our AI and/or machine learning results to the business, and how to use them. Certified instructors from NVIDIA apparently also face simular issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection for Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detection is useful in any domain you can think of, but more fluffy for me to grasp when done on image detection. Transfer learning will therefore take some time, especially because I didn't manage to train the models during the lab. Oh yeah, attending the leading GPU tech summit where your servers fail you.\n",
    "\n",
    "In any case, learning something about probabilistic autoencoders. As you have a normally distributed variable with a mean and variance, you sample them and produce a latent vector, which becomes your autoencoder. This was you can detect anomalies without labels. \n",
    "\n",
    "My standing question here is what do you if you don´t have a normally distributed variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genomics: Using Deep Learning to Accelerate the Idenfitication of Genetic Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still a standing question after this one: Why are simulated variabs that are more frequent than their real counterpars most likely pathogenic. I had a lively discussion with my neighbour attendees regarding this one, and we tried to get several instructors to tackle it, but haven´t really succeeded.\n",
    "\n",
    "Great code that´s very readable and will for sure get reused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Necessity of Explainability Explained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too much for me to grasp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Keynotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jensen Huang (Founder & CEO @NVIDIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gave a great and inpirational keynote about the current state of tech advances and challenges of using artifical intelligence in the world as well as in the gaming industry. His passion and energy throughout one and a half hours of interchangeably discussing the current state and applications of data science, and advances in GPU computing, was remarkable. \n",
    "Showcasing of real time video generation on the debatable picture of Niel Armstrong on the moon taken by Buzz Aldrin was one of my top moments. While Jensen was talking, his backstage team was simulating the sun rotation and resulting reflections and shadows that were captured on the famous picture.\n",
    "\n",
    "<img src=\"files/images/jensen.png\">\n",
    "\n",
    "Besides that, he nicely summarized the job of a data scientist in the era of new allmighty GPUs as clicking the run button and drinking coffee while your code stuff runs. Not so much (or not yet), but let's see!\n",
    "\n",
    "Had a brief follow up chat with him about the state of the world in the Expo section :)\n",
    "\n",
    "<img src=\"files/images/chat.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jurgen Schmidthuber (Scientific Director @IDSIA)\n",
    "gave a great perspective and cross cut through historical events (biological evolution) that lead to current tech revolution. He also put a great perspective of existance of artifical intelligence since the 1960s, but limited applicablity until the recent advances in computing power. Moreover, he had a nice memory line picture walk to his encounter with Jensen (see above keynote) some 10 years back, when NIVIDA was all about gaming and nothing about computing. He modestly implied Jensen was inspired by him to turn to deep learning.\n",
    "\n",
    "A nice take away from this one on how to chose the next task for AI if you don´t have one on the belt: it should be the one that breaks the capacity but not the skillset of the current most advanced problem solver.\n",
    "\n",
    "I´m assuming everyone and not just me was left with distopian thoughts about the speed of tech evolution, and AI evolving and expanding into the universe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pannel discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I only joined this one:\n",
    "\n",
    "### How to Create Talented Teams and Deliver Successful AI Solutions\n",
    "Staring:\n",
    "* Miachael Holmstroem (Managing Director @Academy.se)\n",
    "* Will Ramey (Senior Director Gloval Head of Developer Programs @NVIDIA)\n",
    "* Timo Stich (Senior Research Scientist @ZEISS) >>> Love the guys' name!\n",
    "* Ulli Waltinger (CT Research in Digitalization and Automation @Siemens)\n",
    "* Wes McKinney (Director @Ursa Labs, PMC @Apache Arrow, brain behing python pandas)\n",
    "\n",
    "In many ways a nice pannel discussion, where every single one of the pannelists confirmed that data connentivity is by far the biggest issue in data science today (sounds familiar @Digital Lipase team?). A recommendation was put forward by the pannelists on going for a firm data strategy when you decide to go for a data driven business. First thing's first, you need data governance and data labelling. \n",
    "Than comes machine learning/AI. Mr Waltinger was the strongest advocate of productionalizing POCs as soon as possible, and killing them fast if they don´t work.\n",
    "Regarding the ways of working with and in data science teams, Mr Stich shared his thoughs on the crucial need for every single project team member to understand the whole process end to end, even though they are doing only one task (step) in the project (process). This enables everyone to function more effectively, as it´s easier to relate and see the big picture, instead of running the threadmill like a caged hamster with their task and only their task.\n",
    "\n",
    "Afterwards I felt comforted by the speed of exectution in our data science team, and optimistic about eventually optimizing our ways of working with engaging with the business and delivering data science solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEO @PureStorage on Deploying and Benchmarking Real-World AI Infrastructure \n",
    "\n",
    "Patrick Smith by name, presented a nice analogy of ice ages of AI since 1960s (third peak happening in this decade). In the previous AI warmings, one would have prefered to lose code rather than data as most time and effort was put into producing code. Nowdays one would prefer to lose code, cause you´re mostly reusing anyway, but investing a lot of time into collecting and storing data. Plus relying on data for AI is crutial, because without history there´s no prediction.\n",
    "Ecosystem around ML code is creating a technical debt of AI (need a lot of power and storage space for the tiny bit of the data flow that is the machine learning analytics).\n",
    "\n",
    "\n",
    "All very interesting new ways of thinking about known phenomena, plus very nice and polished slides.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEO @PlantVision on Augmented Reality for Breeding and Optimization of Food and Medicine\n",
    "This was very (too out of this world) visionary. As a biologist by training, I had several issues seeing their mission come true, especially due to biological phenomena like phenotypic plasticity. \n",
    "Check out [their website](http://www.huxley.io/) nevertheless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Expo and demos\n",
    "\n",
    "Had a lot of fun there, including demos of VR for gaming. \n",
    "\n",
    "Real time stylized video technology:\n",
    "<img src=\"files/images/realtimevideo.png\">\n",
    "\n",
    "Future of public transportation with autonomous vehicles:\n",
    "\n",
    "<img src=\"files/images/publictransport.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi ride back to the airport\n",
    "\n",
    "We hitched a ride to the airport with a few guys from NVIDIA, DDG and a fellow data scientist commrade from Nokia. Had some nice follow up discussions on the state of affairs in data storage, computing power, and ethics of using and deplying AI.\n",
    "\n",
    "To sum up, it was a fun few days. So long Munich, and back to reality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you to my sponsors at NZ for financing my conference ticket."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
